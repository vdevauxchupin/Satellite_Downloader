{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GEE_L/S_Downloader.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "awtPNMO2M4Ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd272751-7b42-4075-c8c4-53bd8b43693b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geetools in /usr/local/lib/python3.7/dist-packages (0.6.14)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from geetools) (1.3.5)\n",
            "Requirement already satisfied: pyshp in /usr/local/lib/python3.7/dist-packages (from geetools) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from geetools) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->geetools) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->geetools) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->geetools) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->geetools) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->geetools) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->geetools) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->geetools) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->geetools) (1.24.3)\n",
            "Collecting fiona\n",
            "  Downloading Fiona-1.8.21-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.7 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona) (2021.10.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona) (0.7.2)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona) (21.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona) (57.4.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona) (1.1.1)\n",
            "Installing collected packages: munch, fiona\n",
            "Successfully installed fiona-1.8.21 munch-2.5.0\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.6)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.8)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import ee\n",
        "!pip install geetools\n",
        "import geetools\n",
        "import numpy as np\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import auth\n",
        "!pip install fiona\n",
        "!pip install rasterio\n",
        "from rasterio.merge import merge\n",
        "import rasterio as rio, fiona\n",
        "import rasterio.mask as mask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authorize the access to your Google Drive"
      ],
      "metadata": {
        "id": "bmiQJ46quxqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UKgFG7fAu2Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy-paste your GEE link to import your account/save on the drive"
      ],
      "metadata": {
        "id": "igkaurqLObnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "id": "S38wUrGsM_GZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4c86a3-1597-4c08-c4ff-cbafc99f04aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=wVyFOr4yCNOt0hrCCPi0cLoLDASpQGVAdeTNVpXoRrE&tc=58Ug1FMCCDM56v5--Z3aj4Vc90wcLI_83h1tPs0tmvg&cc=J6ZxT7G_FG9lGZQ8ZDEOdzehFl5Z9UH_L1PJ_jDqOoE\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AX4XfWj3L_ANGeO9zpcdS68nU6o4c3Yw8mQQof8JU93TAmp6PH0vt1cnM9c\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to gather Satellite collections, filter them and download them"
      ],
      "metadata": {
        "id": "3-HrZJK5OWDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions are used to download Landsat 4-8 and Sentinel 2 images depending on a user-defined:\n",
        "\n",
        "- time-window (from which year to which year)\n",
        "- date pattern (eg: between 01/09 - 31/10 of each year)\n",
        "- Area of Interest - AOI (area for which the maximum cloud percentage allows or blocks the image to be downloaded, should be smaller or equal to the ROI)\n",
        "- Region of Interest - ROI (region for which the images are downloaded)\n",
        "- Cloud percentage (will search for images having less or equal to this percentage of cloud covered pixels)\n",
        "- Maximum cloud percentage (the cloud percentage variable will be increased percent by percent until an image is available, or until the maximum cloud percentage is reached)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ebjnX0lPVGYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Depending on the year, will automatically select the available dataset between the set dates\n",
        "\n",
        "def Satellite_collectioner(y, AOI, ROI, foldername, cloudperc, cloudmax, sdate, edate):\n",
        "\n",
        "  # Preload the path to the dataset\n",
        "  ID4 = 'LANDSAT/LT04/C01/T1_SR'\n",
        "  ID5 = \"LANDSAT/LT05/C01/T1_SR\"\n",
        "  ID7 = \"LANDSAT/LE07/C01/T1_SR\"\n",
        "  ID8 = 'LANDSAT/LC08/C01/T1_SR'\n",
        "  IDS = 'COPERNICUS/S2'\n",
        "\n",
        "\n",
        "  # These loops determine which satellite collection to take\n",
        "  if y < 1984:\n",
        "    IDA = ID4\n",
        "    Sat_ID1 = 'L4'\n",
        "\n",
        "  elif y < 1994:\n",
        "    IDA = ID4\n",
        "    IDB = ID5\n",
        "    Sat_ID1 = 'L4'\n",
        "    Sat_ID2 = 'L5'\n",
        "\n",
        "  elif y < 1999:\n",
        "    IDA = ID5\n",
        "    Sat_ID1 = 'L5'\n",
        "\n",
        "  elif y < 2012:\n",
        "    IDA = ID5\n",
        "    IDB = ID7\n",
        "    Sat_ID1 = 'L5'\n",
        "    Sat_ID2 = 'L7'\n",
        "\n",
        "  elif y < 2015:\n",
        "    IDA = ID7\n",
        "    IDB = ID8\n",
        "    Sat_ID1 = 'L7'\n",
        "    Sat_ID2 = 'L8'\n",
        "    \n",
        "  # Between 2015 and 2022, we can download Sentinel-2 images\n",
        "  elif y < 2022:\n",
        "    IDA = ID7\n",
        "    IDB = ID8\n",
        "    IDC = IDS\n",
        "    Sat_ID1 = 'L7'\n",
        "    Sat_ID2 = 'L8'\n",
        "    Sat_ID3 = 'S2'\n",
        "    \n",
        "    # Initialize the percentage of clouds\n",
        "    percloudS2 = 10\n",
        "    cloud = 1\n",
        "\n",
        "    # If percentage of clouds doesn't give any image, we increase it until it reaches cloudmax or finds images\n",
        "    while cloud == 1 and percloudS2 < cloudmax:\n",
        "\n",
        "      try: \n",
        "        S2st = ee.ImageCollection('COPERNICUS/S2').filterBounds(AOI).filter(ee.Filter.date(sdate, edate)).filter(ee.Filter.lessThanOrEquals('CLOUDY_PIXEL_PERCENTAGE', percloudS2))\n",
        "        saverator('S2', S2st, foldername, ROI)\n",
        "        cloud = 0\n",
        "        print('S2 image for {0} with {1}% cloud'.format(y, percloudS2))\n",
        "      except:\n",
        "        percloudS2 += 1\n",
        "      \n",
        "    if cloud == 1:\n",
        "      print('No S2 image for {0}'.format(y))\n",
        "    \n",
        "  # Download the Landsat collections\n",
        "  try:\n",
        "    collection1 = Landsater(IDA, sdate, edate)\n",
        "    saverator(Sat_ID1, collection1, foldername, ROI)\n",
        "    print('{0} image for {1}'.format(Sat_ID1, y))\n",
        "\n",
        "  except: \n",
        "    print('No data for {0} {1}'.format(y, Sat_ID1))\n",
        "\n",
        "\n",
        "  try:\n",
        "    collection2 = Landsater(IDA, sdate, edate)\n",
        "    saverator(Sat_ID2, collection2, foldername, ROI)\n",
        "    print('{0} image for {1}'.format(Sat_ID2, y))\n",
        "\n",
        "  except: \n",
        "    print('No data for {0} {1}'.format(y, Sat_ID2))\n",
        "\n",
        "\n",
        "# Function to save the images on the Google Drive\n",
        "def saverator(Sat_ID, collection, foldername, glob_ROI):\n",
        "\n",
        "    geetools.batch.Export.imagecollection.toDrive(\n",
        "        collection, \n",
        "        folder=foldername,  \n",
        "        namePattern= Sat_ID + '_{system_date}', \n",
        "        dataType=\"float\", \n",
        "        region=glob_ROI.bounds().getInfo()['coordinates'], \n",
        "        datePattern='y_MM_dd',\n",
        "        extra=None, \n",
        "        verbose=False,\n",
        "        #scale = 30   # Force the image to have a footprint of 30m\n",
        "        )\n",
        "\n",
        "\n",
        "# Function used to create the Landsat collection\n",
        "def Landsater(satID, sdate, edate):\n",
        "\n",
        "  collection = ee.ImageCollection(satID).filterDate(sdate, edate).filterBounds(AOI).map(maskQuality)\n",
        "\n",
        "  return collection\n",
        "\n",
        "\n",
        "# Used to compute the bits to extract for the cloud mask\n",
        "def getQABits(image, start, end, mascara):\n",
        "    # Compute the bits we need to extract.\n",
        "    pattern = 0\n",
        "    for i in range(start,end+1):\n",
        "        pattern += 2**i\n",
        "    # Return a single band image of the extracted QA bits, giving the band a new name.\n",
        "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
        "\n",
        "\n",
        "# Cloud mask\n",
        "def maskQuality(image):\n",
        "    # Select the QA band.\n",
        "    QA = image.select('pixel_qa')\n",
        "    # Get the internal_cloud_algorithm_flag bit.\n",
        "    sombra = getQABits(QA,3,3,'cloud_shadow')\n",
        "    nubes = getQABits(QA,5,5,'cloud')\n",
        "    #  var cloud_confidence = getQABits(QA,6,7,  'cloud_confidence')\n",
        "    cirrus_detected = getQABits(QA,9,9,'cirrus_detected')\n",
        "    #var cirrus_detected2 = getQABits(QA,8,8,  'cirrus_detected2')\n",
        "    #Return an image masking out cloudy areas.\n",
        "    return image.updateMask(sombra.eq(0)).updateMask(nubes.eq(0).updateMask(cirrus_detected.eq(0)))\n",
        "\n",
        "\n",
        "# Cloud mask for Sentinel-2\n",
        "def maskS2clouds(image):\n",
        "  QA = image.select('QA60');\n",
        "\n",
        "  #Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "  cloudBitMask = 1 << 10\n",
        "  cirrusBitMask = 1 << 11\n",
        "\n",
        "  #Both flags should be set to zero, indicating clear conditions.\n",
        "  cloud = getQABits(QA, 10, 10, 'cloud')\n",
        "  cirrus = getQABits(QA, 11, 11, 'cirrus_detected')\n",
        "\n",
        "  return image.updateMask(cloud.eq(0)).updateMask(cirrus.eq(0)).divide(10000)\n",
        "\n",
        "\n",
        "# Function to move downloaded images to another folder and reorganize the data\n",
        "def Mover(SAR, foldername):\n",
        "\n",
        "\n",
        "  # We define the source folder to be the one in which the images were downloaded\n",
        "  src_folder = '/content/drive/MyDrive/' + foldername\n",
        "\n",
        "  # Create Optical and SAR subfolders and subsubfolders to hold the downloaded images\n",
        "  if SAR:\n",
        "    os.mkdir(src_folder + '/SAR')\n",
        "    os.mkdir(src_folder + '/SAR/Original')\n",
        "  else:\n",
        "    os.mkdir(src_folder + '/Optical')\n",
        "    os.mkdir(src_folder + '/Optical/Original')\n",
        "\n",
        "\n",
        "  # Depending on if you are working with SAR or Optical, the destination folder will change\n",
        "  if SAR:\n",
        "    dst_folder = src_folder + 'SAR/Original/'\n",
        "  else: \n",
        "    dst_folder = src_folder + 'Optical/Original/'\n",
        "\n",
        "  # Search files with .txt extension in source directory\n",
        "  pattern = \"/*.tif\"\n",
        "  files = glob.glob(src_folder + pattern)\n",
        "\n",
        "  # move the files with txt extension\n",
        "  for file in files:\n",
        "      # extract file name form file path\n",
        "      file_name = os.path.basename(file)\n",
        "      shutil.move(file, dst_folder + file_name)\n",
        "      print('Moved:', file)\n",
        "\n",
        "  return dst_folder"
      ],
      "metadata": {
        "id": "CzR4HFU9M_Wg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use this window to enter your parameters and download the available images over a time-period\n"
      ],
      "metadata": {
        "id": "rHnNHdBkj12D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFIGURE THE DOWNLOAD HERE (beware: an AOI too large will mess-up the Landsat Cloud filtering)\n",
        "\n",
        "AOI is supposed to be smaller than the ROI\n",
        "\n",
        "BE CAREFULE: when you enter a foldername, you can not nest the images in a smaller folder. For example, if you want to put your images in the \"Images\" folder located in the \"Remote_Sensing\" folder, you would write: foldername = \"Remote_Sensing/Images/\". But what the \"to_drive\" GEE function will do is create a folder names \"Remote_Sensing/Images/\". \n",
        "So what I advise is creating a separete folder that will host your downloads, clip together your images, and save the clips in the folder that you want."
      ],
      "metadata": {
        "id": "fYOB1BxAOOa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ROI\n",
        "ROI = ee.Geometry.Polygon([[-141.28,59.66],\n",
        "                               [-139.4,59.66],\n",
        "                               [-139.4,60.7],\n",
        "                               [-141.28,60.7],\n",
        "                               [-141.28,59.66]]);\n",
        "\n",
        "# Define AOI\n",
        "AOI = ee.Geometry.Polygon([[-140.58164857507944,60.064393782012615],\n",
        "                               [-140.1339557039857,60.064393782012615],\n",
        "                               [-140.1339557039857,60.32038533124061],\n",
        "                               [-140.58164857507944,60.32038533124061],\n",
        "                               [-140.58164857507944,60.064393782012615]])\n",
        "\n",
        "# Name of the folder that will host the images on your Drive\n",
        "foldername = 'Projet_Remote_Sensing'\n",
        "# Define a starting cloud percentage\n",
        "cloudperc = 10\n",
        "# Define a max cloud percentage\n",
        "cloudmax = 50\n",
        "\n",
        "\n",
        "# Write starting month/day and ending month/day\n",
        "smd = '09-01'\n",
        "emd = '10-31'\n",
        "\n",
        "# Select starting year and ending year\n",
        "\n",
        "syear = 2018\n",
        "eyear = 2022\n",
        "\n",
        "# Download satellite images between custom range of years\n",
        "for y in range(syear, eyear+1):\n",
        "\n",
        "  # Create the date strings\n",
        "  sdate = str(y) + '-' + smd\n",
        "  edate =  str(y) + '-' + emd\n",
        "\n",
        "  # Launch the main function\n",
        "  Satellite_collectioner(y, AOI, ROI, foldername, cloudperc, cloudmax, sdate, edate)"
      ],
      "metadata": {
        "id": "r418YaPDNC9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42224da0-1d2a-49da-9a18-f4f928fd411c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S2 image for 2018 with 10% cloud\n",
            "S2 image for 2019 with 10% cloud\n",
            "S2 image for 2020 with 10% cloud\n",
            "S2 image for 2021 with 10% cloud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DOWNLOADING MULTIPLE IMAGES MIGHT TAKE A FEW DAYS - COME BACK TO THIS PART AFTER ALL YOUR IMAGES HAVE BEEN DOWNLOADED"
      ],
      "metadata": {
        "id": "j1GF2YTytgF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move the images from their folder to a more organized folder"
      ],
      "metadata": {
        "id": "IKprvj_wtq9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you are working with SAR images, turn SAR to \"True\"\n",
        "# You should already have the foldername defined as in the cells above\n",
        "foldername = 'Projet_Remote_Sensing'\n",
        "SAR = False\n",
        "\n",
        "# Call the mover function to remove the images from the main directory and move them to a subsubfolder\n",
        "# Keep the foldername in which you put the images, useful for later\n",
        "dst_folder = Mover(SAR, foldername)"
      ],
      "metadata": {
        "id": "jBr2ngqVt3cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clip the images together\n",
        "\n",
        "If your ROI is large, you might be overlapping over several Landsat or Sentinel paths. You might have different images covering a big region that you should clip together to transform them into 1 image.\n",
        "\n",
        "The following code does that, by clipping together all the images from a same sensor (Landsat or Sentinel) taken the same day. \n"
      ],
      "metadata": {
        "id": "rvR0mRCTxJmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assembler takes raster within the same defined time-window  and nanmeans them\n",
        "def assembler(array_host, raster2, lim_band):\n",
        "\n",
        "  # Open the 2nd raster to merge as an array\n",
        "  raster2 = rio.open(raster2, 'r').read()\n",
        "\n",
        "  # Create a host array that will be the nanmean of the two other rasters. lim_band is the amount of band per sensor \n",
        "  raster = np.zeros((lim_band, array_host.shape[1], array_host.shape[2]))\n",
        "\n",
        "  # Fill-in the host array with the different images\n",
        "  for i in range(lim_band):\n",
        "      raster[i, :, :] = np.nanmean(np.dstack((array_host[i, :, :], raster2[i,:,:])),2)\n",
        "\n",
        "  return(raster)\n",
        "  \n",
        "\n",
        "# Merges a variable amount of rasters, clips them with the outline, and saves them as tifs\n",
        "def merger(list_similar, name_merge, folder):\n",
        "\n",
        "  # Initialize the list that will host all the rasters from the same day/satellite\n",
        "  rasters = []\n",
        "\n",
        "  # Put all these images in the same list\n",
        "  for i in list_similar:\n",
        "\n",
        "    raster = rio.open(i, \"r+\", nodata = np.nan)\n",
        "    rasters.append(rio.open(i, \"r+\", nodata = np.nan))\n",
        "\n",
        "  # Kepp the metadata of a raster as a template (they all have the same CRS and extent)\n",
        "  out_meta = raster.meta\n",
        "\n",
        "  # Use the \"merge\" function from rasterio to merge all rasters\n",
        "  mosaic, output = merge(rasters)\n",
        "\n",
        "  # Write the \"mosaic\" array as a raster so it can be called for the function clipping the glacier mask to it\n",
        "  with rio.open(folder + '/' + name_merge + '.tif', \"w\", **out_meta) as dest:\n",
        "      dest.write(mosaic)\n",
        "\n",
        "  # Open this array as a raster, overwrite the previous array to save memory\n",
        "  mosaic = rio.open(folder + '/' + name_merge + '.tif', \"r+\", nodata = np.nan)\n",
        "\n",
        "  # Use the \"Clipper\" function to clip to the merged raster the glacier mask (everything outside of glacier mask is NaN)\n",
        "  mosaic, passaran = Clipper(mosaic, 'Glacier')\n",
        "\n",
        "  # If the file is empty (passaran = 0): delete the tif in the output folder\n",
        "  if passaran == 1:\n",
        "    with rio.open(folder + '/' + name_merge + '.tif', \"w\", **out_meta) as dest:\n",
        "          dest.write(mosaic)\n",
        "  \n",
        "  else:\n",
        "    os.remove(folder + '/' + name_merge + '.tif')\n",
        "\n",
        "  \n",
        "# Clip Randolf's outline\n",
        "def Clipper(raster, option, metadata):\n",
        "\n",
        "  # We define different \"zones\" to clip because we are working with 3 main tributaries.\n",
        "  # If we don't do that, the ELA searching algorithm can give messed up results. \n",
        "\n",
        "  # Used to clip the raster to the glacier's extend \n",
        "  if option == 'Glacier':\n",
        "    path = '/content/drive/MyDrive/Projet_Remote_Sensing/Outlines/glacier.shp'\n",
        "\n",
        "  # Used to calculate an average value in the accumulation area of the Agassiz    \n",
        "  elif option == 'Agassiz': \n",
        "    path = '/content/drive/MyDrive/Projet_Remote_Sensing/Outlines/Shapes/Acc/Acc_Agassiz.shp'\n",
        "\n",
        "  # Used to calculate an average value in the accumulation area of the Seward  \n",
        "  elif option == 'Seward':\n",
        "    path = '/content/drive/MyDrive/Projet_Remote_Sensing/Outlines/Shapes/Acc/Acc_Seward.shp'\n",
        "\n",
        "  # Used to calculate an average value in the accumulation area of the Marvine\n",
        "  elif option == 'Marvine':\n",
        "    path = '/content/drive/MyDrive/Projet_Remote_Sensing/Outlines/Shapes/Acc/Acc_Marvine.shp'\n",
        "\n",
        "  # Is used to calculate an average value in the ablation shape\n",
        "  elif option == 'Ablation':\n",
        "    path = '/content/drive/MyDrive/Projet_Remote_Sensing/Outlines/Shapes/Abl/Abl.shp'\n",
        "\n",
        "  \n",
        "  # Read Shapefile\n",
        "  with fiona.open(path, \"r\") as shapefile:\n",
        "      shapes = [feature[\"geometry\"] for feature in shapefile]\n",
        "\n",
        "\n",
        "  # read imagery file\n",
        "  out_image, out_transform = mask.mask(raster, shapes, crop=True, nodata=np.nan)\n",
        "\n",
        "  # Check that after the clip, the image is not empty\n",
        "  test = out_image[~np.isnan(out_image)]\n",
        "\n",
        "  if test[test > 0].shape[0] == 0:\n",
        "      raise RuntimeError(\"Empty output\")\n",
        "\n",
        "  out_meta = raster.profile\n",
        "  out_meta.update({\"height\": out_image.shape[1],\n",
        "                    \"width\": out_image.shape[2],\n",
        "                    \"transform\": out_transform})\n",
        "\n",
        "\n",
        "  if test[test>0].shape[0] == 0:\n",
        "    passaran = 0\n",
        "  else:\n",
        "    passaran = 1\n",
        "\n",
        "  # convert the zeros into NaNs\n",
        "  \n",
        "  return(out_image, passaran, metadata)\n",
        "\n",
        "\n",
        "# This function will allow to merge/clip optical images (only merge or clip) or simply clip SAR images\n",
        "# (SAR images are already downloaded from the same path, so no merging is necessary)\n",
        "def Master_Clipper(list_names, path, SAR):\n",
        "\n",
        "  if SAR:\n",
        "      # Read glacier outline file\n",
        "      with fiona.open('/content/drive/MyDrive/Projet_Remote_Sensing/Outlines/glacier.shp', \"r\") as shapefile:\n",
        "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
        "\n",
        "  # Initialize the counter of the loop      \n",
        "  i = 0\n",
        "\n",
        "  while i < len(list_names):\n",
        "    # If SAR\n",
        "    if SAR:\n",
        "      # Get the names in the SAR images folder\n",
        "      name = list_names[i].split('/')[-1][:8]\n",
        "\n",
        "      # Open the first image as a reference to grab its metadata\n",
        "      raster = rio.open(list_names[i], \"r+\", nodata = np.nan)\n",
        "      out_meta = raster.meta\n",
        "\n",
        "      # read imagery file and clip the glacier extent\n",
        "      out_image, out_transform = rio.mask.mask(raster, shapes, crop=True, nodata = np.nan)\n",
        "\n",
        "      # Check that after the clip, the image is not empty\n",
        "      test = out_image[~np.isnan(out_image)]\n",
        "\n",
        "      # If the image is empty, it will be deleted\n",
        "      if test[test>0].shape[0] == 0:\n",
        "        passaran = 0\n",
        "      else:\n",
        "        passaran = 1\n",
        "\n",
        "      if passaran == 1:\n",
        "\n",
        "        with rio.open(path + '/' + name + '.tif', \"w\", **out_meta) as dest:\n",
        "              dest.write(out_image)\n",
        "\n",
        "      else:\n",
        "        os.remove(path + '/' + name + '.tif')\n",
        "\n",
        "      # We increment the loop\n",
        "      i += 1\n",
        "\n",
        "    # If Optical\n",
        "    else:\n",
        "\n",
        "      # First, gather all the images from the same months\n",
        "      list_similar = sorted(glob.glob(list_names[i].split('_')[0] + '_' + list_names[i].split('_')[1] + '_' + list_names[i].split('_')[2] + '_' + list_names[i].split('_')[3] + '_' + list_names[i].split('_')[4] +'*'))\n",
        "      name = list_similar[-1].split('/')[-1]\n",
        "\n",
        "      # Merge Rasters with same date  \n",
        "      try: \n",
        "        merger(list_similar, name, path)\n",
        "        print('File {0} merged successfully'.format(i))\n",
        "      except:\n",
        "        print('File {0} could not be processed'.format(i))\n",
        "      \n",
        "      # Increment the loop by the length of files with the same name for a given day\n",
        "      i += len(list_similar)\n",
        "  "
      ],
      "metadata": {
        "id": "uvi93bFAkTLN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function call will first merge all rasters becoming to the same satellite taken on the same day, then it will clip them all to the Glacier Mask from the Randolph Glacier inventory.\n",
        "\n",
        "Be aware, I encountered issues while clipping the glacier mask. Sometimes it works and sometimes it does not, for reasons unknown and by using the exact same lines of code both times: [GIS stack topic](https://gis.stackexchange.com/questions/429578/python-cropping-a-tiff-with-shapefile-shifts-the-output-slightly-to-the-east/429586#429586)"
      ],
      "metadata": {
        "id": "RclgyOhxiExN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop that gathers rasters with the same date from the destination folder defined during the moving of the images\n",
        "list_names = sorted(glob.glob(dst_folder + '*'))\n",
        "\n",
        "# Depending on if you use SAR images, the path will be automatically determined\n",
        "if SAR:\n",
        "  path = '/content/drive/MyDrive/Projet_Remote_Sensing/SAR/Clipped_Images'\n",
        "else: \n",
        "  path = '/content/drive/MyDrive/Projet_Remote_Sensing/Optical/Clipped_Images'\n",
        "\n",
        "Master_Clipper(list_names, path, SAR)"
      ],
      "metadata": {
        "id": "KvdyUYE6qLYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}